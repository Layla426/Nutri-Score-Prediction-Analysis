{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/d7rhktfx23s7f0t994bd2j500000gn/T/ipykernel_37406/2758970970.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('openfoodfacts_cleaned.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('openfoodfacts_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Choosing Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_countries_categories = df['countries_en'].unique()\n",
    "# The output is: Number of unique categories in 'countries_en': 5529\n",
    "\n",
    "# Select the top 5 countries with the largest sample size to focus on the most prominent patterns\n",
    "# This helps in capturing the main features of countries and reduces the influence of noise\n",
    "selected_countries = ['France', 'United States', 'Italy', 'Spain', 'Germany']\n",
    "df = df[df['countries_en'].isin(selected_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remain columns I want to explore further\n",
    "columns_needed = [\n",
    "    'countries_en', 'food_groups_en', 'nutriscore_score','energy-kcal_100g', 'saturated-fat_100g', \n",
    "    'sugars_100g', 'sodium_100g', 'proteins_100g', 'fiber_100g', 'fruits-vegetables-nuts-estimate-from-ingredients_100g'\n",
    "]\n",
    "\n",
    "# extract coulumns \n",
    "df = df[columns_needed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to reuse them briefly\n",
    "df = df.rename(columns={\n",
    "    'fruits-vegetables-nuts-estimate-from-ingredients_100g': 'FVN_estimate',\n",
    "    'saturated-fat_100g': 'sat_fat',\n",
    "    'energy-kcal_100g': 'energy_kcal',\n",
    "    'sugars_100g': 'sugar',\n",
    "    'sodium_100g': 'sodium',\n",
    "    'proteins_100g': 'protein',\n",
    "    'fiber_100g': 'fiber',\n",
    "    'countries_en': 'countries',\n",
    "    'food_groups_en': 'food_groups',\n",
    "    'nutriscore_score': 'nutriscore'  \n",
    "})\n",
    "\n",
    "# Output the updated column names to check\n",
    "print (df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where 'nutrition-score-fr_100g' (Nutri-score) column has missing values\n",
    "df = df[df['nutriscore'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values in 'fiber_100g' and 'fruits-vegetables-nuts-estimate-from-ingredients_100g'\n",
    "df_cleaned = df.dropna(subset=['fiber', 'FVN_estimate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'food_groups_en' column has missing values\n",
    "df_cleaned = df_cleaned.dropna(subset=['food_groups'])\n",
    "\n",
    "print(f\"Number of rows and columns in the dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'nutriscore_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the range of Nutri-Score\n",
    "min_value = df['nutriscore'].min()\n",
    "max_value = df['nutriscore'].max()\n",
    "\n",
    "print(f\"Range of nutriscore_score: {min_value} to {max_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Food_groups_en' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'food_groups_en' is 'Unknown' or 'Alcoholic beverages'\n",
    "# These categories have too few samples to have a significant impact on the analysis\n",
    "df = df[~df['food_groups'].isin(['Unknown', 'Alcoholic beverages'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### energy-kcal_100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize the distribution of 'energy-kcal_100g'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['energy_kcal'])\n",
    "plt.title('Boxplot of energy_kcal')\n",
    "plt.xlabel('energy_kcal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the 'energy-kcal_100g' column has values greater than 1000\n",
    "df = df[df['energy_kcal'] <= 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saturated-fat_100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize the distribution of 'saturated-fat_100g'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['sat_fat'])\n",
    "plt.title('Boxplot of sat_fat')\n",
    "plt.xlabel('sat_fat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the 'saturated-fat_100g' column has values greater than 1000\n",
    "df = df[df['sat_fat'] <= 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sugars_100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize the distribution of 'sugars_100g'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['sugar'])\n",
    "plt.title('Boxplot of sugar')\n",
    "plt.xlabel('sugar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the 'sugars_100g' column has values greater than 100\n",
    "df = df[df['sugar'] <= 100]\n",
    "# Print the shape of the filtered dataset to confirm the number of rows and columns\n",
    "print(f\"Filtered dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sodium_100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize the distribution of 'sodium_100g'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df_cleaned['sodium'])\n",
    "plt.title('Boxplot of sodium')\n",
    "plt.xlabel('sodium')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of food categories where higher sodium content (>3g/100g) is considered reasonable\n",
    "valid_categories = [\n",
    "    'Fats and sauces,Dressings and sauces',\n",
    "    'Composite foods,One-dish meals',\n",
    "    'Salty snacks, Salty and fatty products',\n",
    "    'Milk and dairy products, Cheese'\n",
    "]\n",
    "\n",
    "# Remove rows where 'sodium_100g' > 3g/100g that do not belong to valid categories\n",
    "df = df[~((df['sodium'] > 3) & (df['food_groups'].apply(lambda x: x not in valid_categories)))]\n",
    "\n",
    "# Print the shape of the filtered dataset to confirm the number of rows and columns\n",
    "print(f\"Filtered dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### proteins_100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize the distribution of 'proteins_100gâ€˜\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['protein'])\n",
    "plt.title('Boxplot of protein')\n",
    "plt.xlabel('protein')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the 'sugars_100g' column has values greater than 100\n",
    "df = df[df['protein'] <= 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fiber_100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize the distribution of 'fiber_100gâ€˜\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['fiber'])\n",
    "plt.title('Boxplot of fiber')\n",
    "plt.xlabel('fiber')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the 'sugars_100g' column has values greater than 100\n",
    "df = df[df['fiber'] < 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fruits-vegetables-nuts-estimate-from-ingredients_100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize the distribution of 'fruits-vegetables-nuts-estimate-from-ingredients_100g'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['FVN_estimate'])\n",
    "plt.title('Boxplot of FVN_estimate')\n",
    "plt.xlabel('FVN_estimate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the 'fruits-vegetables-nuts-estimate-from-ingredients_100g' column has values greater than 100\n",
    "\n",
    "df = df[df['FVN_estimate'] <= 100]\n",
    "df = df[df['FVN_estimate'] >= 0]\n",
    "\n",
    "# Print the shape of the filtered dataset to confirm the number of rows and columns\n",
    "print(f\"Filtered dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the food groups into broader, fewer categories ï¼ˆpart of feature engineeringï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column by extracting the part before the last comma of 'food_groups_en'  \n",
    "df['food_groups_new'] = df['food_groups'].str.rsplit(',', n=1).str[0]\n",
    "\n",
    "print(df_cleaned[['food_groups', 'food_groups_new']].head())\n",
    "\n",
    "# Replace specified categories with 'Fish, Meat, Eggs'\n",
    "df['food_groups_new'] = df['food_groups_new'].replace(\n",
    "    ['Fishâ€š Meatâ€š Eggs,Fish and seafood', 'Fishâ€š Meatâ€š Eggs', 'Fishâ€š Meatâ€š Eggs,Meat'],\n",
    "    'Fish, Meat, Eggs')\n",
    "\n",
    "# Check the unique values after the replacement\n",
    "print(df['food_groups_new'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with specific categories\n",
    "df['food_groups_new'] = df['food_groups_new'].replace(\n",
    "    ['Fishâ€š Meatâ€š Eggs,Fish and seafood', 'Fishâ€š Meatâ€š Eggs', 'Fishâ€š Meatâ€š Eggs,Meat'],\n",
    "    'Fish, Meat, Eggs')\n",
    "\n",
    "# Check the results after processing\n",
    "print(df['food_groups_new'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['food_groups'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into 85% training and tuning set, 15% final Test set\n",
    "train_set, final_test_set = train_test_split(df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the training set to a CSV file\n",
    "train_set.to_csv('train_set.csv', index=False)  \n",
    "\n",
    "# Export the final Test set to a CSV file\n",
    "final_test_set.to_csv('final_test_set.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  train data\n",
    "train_df = pd.read_csv('/content/drive/MyDrive/laylatest/train_set.csv')\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test data \n",
    "test_df = pd.read_csv('/content/drive/MyDrive/laylatest/final_test_set.csv')\n",
    "\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding 'countries' by Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "country_label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'countries_en' column in the dataset\n",
    "train_df['countries_encoded'] = country_label_encoder.fit_transform(train_df['countries'])\n",
    "\n",
    "# Verify the encoding\n",
    "print(train_df[['countries', 'countries_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding â€˜food_groupsâ€™ by Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "food_label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'food_groups_en' column in the dataset\n",
    "train_df['food_groups_encoded'] = food_label_encoder.fit_transform(train_df['food_groups_new'])\n",
    "\n",
    "# Verify the encoding\n",
    "print(train_df[['food_groups_new', 'food_groups_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Standardize column names and remove unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace special characters in column names with '_'\n",
    "train_df.columns = [re.sub('[^A-Za-z0-9_]+', '_', col) for col in train_df.columns]\n",
    "\n",
    "train_df.drop(columns=['countries', 'food_groups_new'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the final test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding 'countries' by Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "country_label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'countries_en' column in the dataset\n",
    "test_df['countries_encoded'] = country_label_encoder.fit_transform(test_df['countries'])\n",
    "\n",
    "# Verify the encoding\n",
    "print(test_df[['countries', 'countries_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding â€˜food_groupsâ€™ by Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "food_label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'food_groups_en' column in the dataset\n",
    "test_df['food_groups_encoded'] = food_label_encoder.fit_transform(test_df['food_groups_new'])\n",
    "\n",
    "# Verify the encoding\n",
    "print(test_df[['food_groups_new', 'food_groups_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Standardize column names and remove unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace special characters in column names with '_'\n",
    "test_df.columns = [re.sub('[^A-Za-z0-9_]+', '_', col) for col in test_df.columns]\n",
    "# Remove unnecessary columns and remain encoded columns \n",
    "test_df.drop(columns=['countries', 'food_groups_new'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the test dataset aside and only use it to test the final model performance after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test_df into features (X) and target (y)\n",
    "X_test = test_df.drop(columns=['nutriscore'])\n",
    "y_test = test_df['nutriscore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split and Mean Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train_df into features (X) and target (y)\n",
    "X = train_df.drop(columns=['nutriscore'])\n",
    "y = train_df['nutriscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the target variable from the training data\n",
    "mean_baseline = np.mean(y)\n",
    "print(f'Mean Baseline Value (calculated from training data): {mean_baseline}')\n",
    "\n",
    "# Create baseline predictions for the test data (mean of training data)\n",
    "baseline_predictions = np.full(len(y_test), mean_baseline)  # Use the mean of y_train to predict all test data\n",
    "\n",
    "# Calculate evaluation metrics on the validation data\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
    "mse = mean_squared_error(y_test, baseline_predictions)\n",
    "r2_baseline = r2_score(y_test, baseline_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "print(f'MAE for Baseline Model: {mae_baseline}')\n",
    "print(f'MSE for the Baseline Model: {mse}')\n",
    "print(f'RÂ² for Baseline Model: {r2_baseline}')\n",
    "print(f'RMSE for Baseline Model: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model (Before Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost Regressor with default parameters\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation with MAE as the metric\n",
    "cv_mae_scores = -cross_val_score(xgb_model, X, y, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "\n",
    "mean_mae = cv_mae_scores.mean()\n",
    "print(f'MAE for the baseline XGBoost model:{mean_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine appropriate hyperparameter ranges --- Learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of n_estimators to explore its effect on model performance\n",
    "n_estimators_range = [50, 100, 150, 200, 250, 300, 400]\n",
    "\n",
    "# Initialize lists to store training and test errors for each n_estimators value\n",
    "train_mae_scores = []\n",
    "val_mae_scores = []\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    # Create an XGBoost model with the current n_estimators and fixed max_depth\n",
    "    model = xgb.XGBRegressor(n_estimators=n, max_depth=6, learning_rate=0.1, random_state =42)\n",
    "\n",
    "    # Calculate MAE on validation dataset of every k-fold and append to the list (as MAE on test data)\n",
    "    val_mae = -cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    val_mae_scores.append(val_mae.mean())\n",
    "\n",
    "    # Calculate training error and append to the list\n",
    "    model.fit(X, y)\n",
    "    train_mae = mean_absolute_error(y, model.predict(X))\n",
    "    train_mae_scores.append(train_mae)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_range, train_mae_scores, label=\"Training MAE\", color=\"blue\")\n",
    "plt.plot(n_estimators_range, val_mae_scores, label=\"Validation MAE\", color=\"orange\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.title(\"Learning Curve for n_estimators\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the steps above for max_depth to explore its effect on model performance\n",
    "train_mae_scores = []\n",
    "val_mae_scores = []\n",
    "\n",
    "# Define the range of max_depth to explore its impact\n",
    "max_depth_range = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    # Create an XGBoost model with the current max_depth and fixed n_estimators\n",
    "    model = xgb.XGBRegressor(n_estimators=150, max_depth=depth, learning_rate=0.1, random_state =42)\n",
    "\n",
    "    # Use cross-validation to obtain validation MAE\n",
    "    val_mae = -cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    val_mae_scores.append(val_mae.mean())\n",
    "\n",
    "    # Calculate MAE on training data\n",
    "    model.fit(X, y)\n",
    "    train_mae = mean_absolute_error(y, model.predict(X))\n",
    "    train_mae_scores.append(train_mae)\n",
    "\n",
    "# Plot learning curve for max_depth\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depth_range, train_mae_scores, label=\"Training MAE\", color=\"blue\")\n",
    "plt.plot(max_depth_range, val_mae_scores, label=\"Validation MAE\", color=\"orange\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.title(\"Learning Curve for max_depth\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization by Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search ï¼ˆ19min 47s)\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200, 250],          # Number of boosting rounds (trees)\n",
    "    'max_depth': [ 5, 6, 7],                 # Maximum depth of each tree\n",
    "    'learning_rate': [0.01, 0.05, 0.1],           # Learning rate\n",
    "    'min_child_weight': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_absolute_error',  # Scoring metric\n",
    "    cv=5,                               # 5-fold cross-validation\n",
    "    verbose=1,                          # Display progress\n",
    "    n_jobs=-1                           # Use all available cores\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "best_params_xgboost = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params_xgboost}\")\n",
    "\n",
    "# Get the best estimator (model with best hyperparameters)\n",
    "best_xgb_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance on all Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize the model with the best parameters and fit it on the entire training set\n",
    "best_xgb_model = xgb.XGBRegressor(**best_params_xgboost, random_state=42)\n",
    "best_xgb_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = best_xgb_model.predict(X)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "train_mae = mean_absolute_error(y, y_train_pred)\n",
    "train_mse = mean_squared_error(y, y_train_pred)\n",
    "train_r2 = r2_score(y, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "# Print the results for the training set\n",
    "print(f\"MAE on the training set: {train_mae}\")\n",
    "print(f\"MSE on the training set: {train_mse}\")\n",
    "print(f\"RMSE on the training set: {train_rmse}\")\n",
    "print(f\"RÂ² on the training set: {train_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost performance on test data with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model on the test set\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print the results\n",
    "print(f\"MAE for the best XGBoost model: {mae}\")\n",
    "print(f\"MSE on the final test data: {mse}\")\n",
    "print(f\"RMSE on the training set: {rmse}\")\n",
    "print(f\"RÂ² on the final test data: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model (Before Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LightGBM Regressor with default parameters\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation with MAE as the metric\n",
    "cv_mae_scores = -cross_val_score(lgb_model, X, y, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "\n",
    "mean_mae = cv_mae_scores.mean()\n",
    "print(f'MAE for the baseline LightGBM model:{mean_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine appropriate hyperparameter ranges --- Learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of n_estimators to explore\n",
    "n_estimators_range = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "# Initialize lists to store training and validation errors for each n_estimators value\n",
    "train_mae_scores = []\n",
    "val_mae_scores = []\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    # Create a LightGBM model with the current n_estimators\n",
    "    model = lgb.LGBMRegressor(n_estimators=n, max_depth=6, learning_rate=0.1, num_leaves=30, random_state=42)\n",
    "\n",
    "    # Calculate MAE on validation dataset of every k-fold and append to the list (as MAE on validation data)\n",
    "    val_mae = -cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    val_mae_scores.append(val_mae.mean())\n",
    "\n",
    "    # Fit model on entire training data and calculate MAE for training set\n",
    "    model.fit(X, y)\n",
    "    train_mae = mean_absolute_error(y, model.predict(X))\n",
    "    train_mae_scores.append(train_mae)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_range, train_mae_scores, label=\"Training MAE\", color=\"blue\")\n",
    "plt.plot(n_estimators_range, val_mae_scores, label=\"Validation MAE\", color=\"orange\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.title(\"Learning Curve for LightGBM n_estimators\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the steps above for max_depth to explore its effect on model performance\n",
    "train_mae_scores = []\n",
    "val_mae_scores = []\n",
    "\n",
    "# Define the range of max_depth to explore its impact\n",
    "max_depth_range = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    # Create an LightGBM model with the current max_depth and fixed n_estimators\n",
    "    model = lgb.LGBMRegressor (n_estimators=150, max_depth=depth, learning_rate=0.1, num_leaves=30, random_state =42)\n",
    "\n",
    "    # Use cross-validation to obtain validation MAE\n",
    "    val_mae = -cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    val_mae_scores.append(val_mae.mean())\n",
    "\n",
    "    # Calculate MAE on training data\n",
    "    model.fit(X, y)\n",
    "    train_mae = mean_absolute_error(y, model.predict(X))\n",
    "    train_mae_scores.append(train_mae)\n",
    "\n",
    "# Plot learning curve for max_depth\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depth_range, train_mae_scores, label=\"Training MAE\", color=\"blue\")\n",
    "plt.plot(max_depth_range, val_mae_scores, label=\"Validation MAE\", color=\"orange\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.title(\"Learning Curve for max_depth\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### num_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of num_leaves to explore\n",
    "num_leaves_range = [20, 30, 40, 50, 60]\n",
    "\n",
    "# Initialize lists to store training and validation errors for each num_leaves value\n",
    "train_mae_scores = []\n",
    "val_mae_scores = []\n",
    "\n",
    "for num_leaves in num_leaves_range:\n",
    "    # Create a LightGBM model with the current num_leaves\n",
    "    model = lgb.LGBMRegressor(num_leaves=num_leaves, n_estimators=150, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "\n",
    "    # Calculate MAE on validation dataset of every k-fold and append to the list (as MAE on validation data)\n",
    "    val_mae = -cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    val_mae_scores.append(val_mae.mean())\n",
    "\n",
    "    # Fit model on entire training data and calculate MAE for training set\n",
    "    model.fit(X, y)\n",
    "    train_mae = mean_absolute_error(y, model.predict(X))\n",
    "    train_mae_scores.append(train_mae)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_leaves_range, train_mae_scores, label=\"Training MAE\", color=\"blue\")\n",
    "plt.plot(num_leaves_range, val_mae_scores, label=\"Validation MAE\", color=\"orange\")\n",
    "plt.xlabel(\"num_leaves\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.title(\"Learning Curve for LightGBM num_leaves\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization by Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search (20min 14s)\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200, 250],              # Number of boosting rounds (trees)\n",
    "    'max_depth': [5, 6, 7, 8],                  # Maximum depth of each tree\n",
    "    'learning_rate': [0.01, 0.05, 0.1],            # Learning rate\n",
    "    'num_leaves': [30, 40, 50]                 # Number of leaves in one tree\n",
    "    # 'min_child_samples': [10, 20, 30],           # Minimum number of samples in a child (leaf)\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                         # 5-fold cross-validation\n",
    "    scoring='neg_mean_absolute_error',  # Evaluation metric\n",
    "    verbose=1,                    # Display progress\n",
    "    n_jobs=-1                     # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params_LightGBM = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params_LightGBM}\")\n",
    "\n",
    "# Get the best estimator (model with the best hyperparameters)\n",
    "best_lgb_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance on all Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize the model with the best parameters and fit it on the entire training set\n",
    "best_lgb_model = lgb.LGBMRegressor(**best_params_LightGBM, random_state=42)\n",
    "best_lgb_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = best_lgb_model.predict(X)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "train_mae = mean_absolute_error(y, y_train_pred)\n",
    "train_mse = mean_squared_error(y, y_train_pred)\n",
    "train_r2 = r2_score(y, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "# Print the results for the training set\n",
    "print(f\"MAE on the training set: {train_mae}\")\n",
    "print(f\"MSE on the training set: {train_mse}\")\n",
    "print(f\"RMSE on the training set: {train_rmse}\")\n",
    "print(f\"RÂ² on the training set: {train_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM performance on test data with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = best_lgb_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print the results\n",
    "print(f\"MAE for the best LightGBM model: {mae}\")\n",
    "print(f\"MSE for the best LightGBM model: {mse}\")\n",
    "print(f\"RÂ² for the best LightGBM model: {r2}\")\n",
    "print(f\"RMSE for the best LightGBM model: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and validation data to NumPy arrays (TabNet requires NumPy arrays)\n",
    "X_np = X.values\n",
    "X_test_np = X_test.values\n",
    "\n",
    "# Reshape y_train and y_val to 2D arrays (TabNet expects 2D targets)\n",
    "y_np = y.values.reshape(-1, 1)  # Reshape y_train\n",
    "y_test_np = y_test.values.reshape(-1, 1)      # Reshape y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TabNet with default parameters (1h+)\n",
    "tabnet_model = TabNetRegressor(device_name='cuda',verbose=1, seed=42)\n",
    "\n",
    "\n",
    "# Perform 5-fold cross-validation with MAE as the metric\n",
    "cv_mae_scores = -cross_val_score(tabnet_model, X_np, y_np, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "\n",
    "# Calculate the mean MAE from the cross-validation\n",
    "mean_mae = cv_mae_scores.mean()\n",
    "print(f'MAE for the baseline TabNet model: {mean_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization by Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_d': [8, 16, 24, 32],               # Dimensionality of the decision prediction layer\n",
    "    'n_a': [8, 16, 24, 32],               # Dimensionality of the attention embedding for each mask\n",
    "    'n_steps': [3, 5, 7],             # Number of steps in the architecture\n",
    "    'gamma': [1.0, 1.5],         # Scaling factor for the attention updates\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tabnet_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                         # 5-fold cross-validation\n",
    "    scoring='neg_mean_absolute_error',  # Evaluation metric\n",
    "    verbose=1,                    # Display progress\n",
    "    n_jobs=-1                     # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_np, y_np)\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params_tabnet = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params_tabnet}\")\n",
    "\n",
    "# Get the best estimator (model with the best hyperparameters)\n",
    "best_tabnet_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance on all Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize the model with the best parameters and fit it on the entire training set\n",
    "best_tabnet_model = TabNetRegressor(**best_params_tabnet, random_state=42)\n",
    "best_tabnet_model.fit(X_np, y_np)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = best_tabnet_model.predict(X_np)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "train_mae = mean_absolute_error(y_np, y_train_pred)\n",
    "train_mse = mean_squared_error(y_np, y_train_pred)\n",
    "train_r2 = r2_score(y_np, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "# Print the results for the training set\n",
    "print(f\"MAE on the training set: {train_mae}\")\n",
    "print(f\"MSE on the training set: {train_mse}\")\n",
    "print(f\"RMSE on the training set: {train_rmse}\")\n",
    "print(f\"RÂ² on the training set: {train_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TabNet performance on test data with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "y_pred = best_tabnet_model.predict(X_test_np)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test_np, y_pred)\n",
    "mse = mean_squared_error(y_test_np, y_pred)\n",
    "r2 = r2_score(y_test_np, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print the results\n",
    "print(f\"MAE for the best LightGBM model: {mae}\")\n",
    "print(f\"MSE for the best LightGBM model: {mse}\")\n",
    "print(f\"RÂ² for the best LightGBM model: {r2}\")\n",
    "print(f\"RMSE for the best LightGBM model: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP on best-performing model (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best XGBoost model with the optimal parameters\n",
    "best_xgb_model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    n_estimators=250,\n",
    "    random_state=42\n",
    ")\n",
    "# Fit the model on the training data\n",
    "best_xgb_model.fit(X, y)\n",
    "\n",
    "# Create a SHAP explainer for the XGBoost model\n",
    "explainer = shap.TreeExplainer(best_xgb_model)\n",
    "\n",
    "# Calculate SHAP values using the explainer\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SHAP global feature importance as a bar chart\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_global_feature_importance_barplot.png\")\n",
    "plt.clf()\n",
    "\n",
    "# Plot SHAP feature impact as a dot plot\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_global_feature_importance_dotplot.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP Dependence Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure SHAP values are in array format\n",
    "shap_values_array = shap_values.values if hasattr(shap_values, 'values') else shap_values\n",
    "\n",
    "# List of features for SHAP dependence plots\n",
    "feature_list = [\"countries\", \"food_groups\", \"sat_fat\", \"sugar\", \"sodium\", \"fiber\", \"energy_kcal\", \"FVN_estimate\", \"protein\"]\n",
    "\n",
    "# Loop through each feature to create and save SHAP dependence plots\n",
    "for feature in feature_list:\n",
    "    shap.dependence_plot(feature, shap_values_array, X_test, show=False)\n",
    "    plt.title(f\"SHAP Dependence Plot for {feature}\")\n",
    "    plt.ylabel(f\"SHAP Value for {feature}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"shap_dependence_plot_{feature}.png\")\n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
